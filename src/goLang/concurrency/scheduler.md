# Планировщик

Выделяют 3 модели для нарезания вычислений на потоки. 

- **N:1** - несколько пользовательских потоков запущено на едином потоке ядра операционной системы. Этот способ имеет то преимущество, что осуществляется очень быстрое переключение контекстов, но нет возможности воспользоваться преимуществами многоядерных систем. 

- **1:1** - каждый пользовательский поток выполнения совпадает с одним потоком операционной системы. Он использует все ядра автоматически, но переключение контекста происходит медленно, потому что требует прерываний работы операционной системы.

- Go пытается взять лучшее из обоих миров с помощью **М:N** планировщика. При этом произвольное число Go-рутин **M** планируется на произвольное количество потоков **N** операционной системы. Этим вы получаете одновременно быстрое переключение контекста, и возможность воспользоваться всеми ядрами в вашей системе. Основным недостатком данного подхода является сложность его включения в планировщик.  

Планировщик Go использует 3 сущности:

<img src="../../media/go/scheduler_mpg.jpeg" title="" alt="img" data-align="center">

**M Machine**(Треугольник) thread операционной системы. Точнее абстракция над ним, в go runtime представлена в виде структуры. Выполнением такого потока управляет операционная система, и работает это во многом подобно вашим стандартным потокам POSIX. 

- **M** создаются по мере необходимости (но ограничены `GOMAXPROCS`).
- Если горутина блокируется в `syscall`, создается новый **M**.
- System Monitor завершает неиспользуемые M через `forcegc` (чтобы не накапливались лишние потоки).

**G Goroutine**(Круг). Он включает стек, указатель команд и другую важную информацию для планирования горутины, такую как канал, который на ней может быть блокирован. 

**P Processor**(Прямоугольник Планировщик на ядре**. Можно понимать как локальную версию планировщика c собственной очередью горутин под конкретный  **M** c каким-то контекстом(регистры и т.д). 

В планировщике Go есть две разные очереди выполнения:

- глобальная (**GRQ**) 

- локальная (**LRQ**) - может хранит до `256` горутин (**FIFO**) однако, есть такая оптимизация, что последняя горутина, может выполнится первой, без очереди, одноэлементный стэк **LIFO**. Это сделано потому, что, есть ненулевая вероятность, того что на **M** контекст выполнения соотвтетсвует тому, что нужен именно этой горутине, поэтому часто имеет смвсл выполнить её вперёд остальных.

Каждому **P** присваивается **LRQ**, который управляет горутинами, назначенными для выполнения в контексте **P**. Эти горутины по очереди включаются и выключаются из контекста **M**, назначенного для этого **P**. **GRQ** предназначен для горутин, которые не были назначены для **P**. Существует процесс, чтобы переместить горутины из **GRQ** в **LRQ**

![img](../../media/go/scheduler_grq_lrq.png)

Каждая локальная очередь проверяет глобальную каждый 61 такт процессора.

```go
runtime.schedule() {
    // only 1/61 of the time, check the global runnable queue for a G.
    // if not found, check the local queue.
    // if not found,
    //     try to steal from other Ps.
    //     if not, check the global runnable queue.
    //     if not found, poll network.
}
```

Это означает, что **P** будет:

- Существует небольшой шанс(**1/61**) немедленно проверить **GRQ** и запустить горутиную оттуда

- приоритетнее запускать **G** в своем собственном **LRQ**

- затем из **LRQ** других **P**. Воруется `1/2` локальной очереди другого(случайного) **P** (по умолчанию, `128` из `256` возможных). Интересная деталь: **work-stealing** в Go не очень агрессивен, поэтому иногда загрузка ядер может быть неравномерной.

- затем из **GRQ**

- затем из **netpoller**. 

Если горутины нет, поток засыпает (`park()`), а `System Monitor` позже его разбудит.

## Work stealing

 В многопоточных вычислениях, возникли две парадигмы в планировании: 

- **Work-sharing**: Когда процессор генерирует новые потоки, он пытается мигрировать их на другие процессоры, в надежде, что они попадут к простаивающему или недостаточно нагруженному процессору.
- **Work-stealing**: Недостаточно нагруженный процессор активно ищет потоки других процессоров и "крадет" некоторые из них.

Когда новая **G** создается или существующая **G** становится готовой к исполнению, она помещается в локальную очередь готовых к исполнению горутин текущего **P**. Когда **P** заканчивается исполнение **G**, он пытается вытащить **G** из своей очереди. Если список пуст, **P** выбирает случайным образом другой процессор (**P**) и пытается украсть половину горутин из его очереди.

## Вытесняющая многозадачность

Для начала напомню, что такое кооперативная и не кооперативная многозадачность.

С не кооперативной (**вытесняющей**) многозадачностью мы все с вами прекрасно знакомы на примере планировщика ОС. Данный планировщик работает в фоне, выгружает потоки на основании различных эвристик, а вместо выгруженных процессорное время начинают получать другие потоки.

Для **кооперативного** планировщика характерно другое поведение — он спит пока одна из горутин явно не разбудит его с намеком о готовности отдать свое место другой. Планировщик далее сам решит, надо ли убирать из контекста текущую горутину, и если да, кого поставить на ее место. Примерно так и работал планировщик GO.

в **GO** 1.14 изменился принцип работы планировщика, рассмотрим причины по которым эти изменения были сделаны. Взгляните на код:

```go
func main() {
    runtime.GOMAXPROCS(1)
    go func() {
        var u int
        for {
            u -= 2
            if u == 1 {
                break
            }
        }
    }()
    <-time.After(time.Millisecond * 5) // в этом месте main горутина разбудит планировщик, а он в свою очередь запустит горутину с циклом

    fmt.Println("go 1.13 has never been here")
}
```

Если скомпилировать его с версией **GO < 1.14**, то строчку «go 1.13 has never been here» вы на экране не увидите. Происходит это потому, что, как только планировщик дает процессорное время горутине с бесконечным циклом, она всецело захватывает P, внутри этой горутины не происходит ни каких вызовов функций, а значит и планировщик мы больше не разбудим. И только явный вызов runtime.Gosched() даст нашей программе завершиться.

В версии до 1.12 runtime Gosched использовал **safe-points** места, где точно можно вызвать планировщик без боязни, что мы попадем в атомарную для GC секцию кода. Как мы уже говорили, данные safe-points располагаются в прологе функции (но далеко не каждой функции, заметьте). Если вы разбирали go-шный ассемблер, то могли бы возразить — никаких очевидных вызовов планировщика там не видно. Да это так, но вы можете найти там инструкцию вызова **runtime.morestack**, а если заглянуть внутрь этой функции то обнаружится вызов планировщика. 



### Sysmon

Когда горутина делает `syscall`, **M** блокируется. Чтобы не терять вычислительные ресурсы, **P** временно отвязывается (`handoff`), и `System Monitor` выделяет новый **M** для работы с этим **P**.

Когда горутина выполняет блокирующий `syscall` (например, файловый ввод/вывод), поток ОС `M` блокируется. Что происходит дальше:

1. `P` *отвязывается* от заблокированного `M` (`handoff()` в `runtime/proc.go`).
2. `P` начинает искать новый `M`. Если свободных `M` нет, создается новый поток ОС.
3. Когда `syscall` завершится, `M` **не возвращается к своему `P`**, а отправляет горутину в глобальную очередь.
4. `M` либо завершает работу, либо берет новую горутину, если есть свободный `P`.



`sysmon` — это **фоновый поток в Go**, который выполняет несколько задач:

1. **Обнаруживает `M`, зависшие в `syscall`**
   
   - Если `M` завис в `syscall` >10ms, `sysmon` **запускает новый `M`**, чтобы `P` не простаивал.
   - Когда `syscall` завершается, `G` возвращается в очередь, а `M` либо продолжает работать, либо паркуется.

2. **Обслуживает `NetPoller`**
   
   - Обрабатывает **неблокирующие I/O** (`net`, `epoll`, `kqueue`, `IOCP` для Windows).

3. **Пробуждает `P`, если он долго простаивает**
   
   - Если `P` ничего не делал >10ms, `sysmon` **даёт ему работу из глобальной очереди**.

4. **Запускает `forcegc` (форсированный GC)**
   
   - Если горутины долго не доходят до `runtime.GC()`, `sysmon` запускает его принудительно.

### У `syscall` есть своя очередь?

Нет, у `syscall` нет отдельной очереди. Но есть механизм, похожий на очередь:

1. Когда `syscall` завершается, его `M` **помечается как "ready"**.
2. `M` ставит разблокированную горутину в глобальную очередь или передает ее первому свободному `P`.
3. Если `M` остается без работы, он либо уничтожается (`exit0()`), либо переходит в режим ожидания (`park()`).



### Netpoller

**NetPoller** (на базе `epoll/kqueue`) ждет завершения сетевых операций. Если есть активные соединения, он пробуждает соответствующие горутины.

Когда операционная система, на которой вы работаете, имеет возможность обрабатывать системный вызов асинхронно, то, что называется **network poller**, может использоваться для более эффективной обработки системного вызова. Это достигается с помощью **epoll** (Linux), kqueue (MacOS), или iocp (Windows) в этих соответствующих ОС.

Сетевые системные вызовы могут обрабатываться асинхронно многими операционными системами, которые мы используем сегодня. Именно здесь **network poller** показывает себя, поскольку его основное назначение — обработка сетевых операций. Используя **network poller** для сетевых системных вызовов, планировщик может запретить горутинам блокировать **M** при выполнении этих системных вызовов. Это помогает держать **M** доступным для выполнения других горутин в **LRQ** **P** без необходимости создавать новые **M**. Это помогает уменьшить нагрузку планирования в ОС.

#### Как `NetPoller` работает на фоне `syscall`?

`NetPoller` (`runtime.netpoll`) занимается асинхронными операциями (epoll/kqueue/iocp). Разница между ним и обычным `syscall`:

- Если горутина делает **сетевой вызов**, NetPoller **не блокирует `M`**, а просто регистрирует `G`.
- Когда событие готово, `NetPoller` пробуждает горутину и ставит ее в глобальную очередь.

Пример:

- `G1` ждет сокет (`read()`), `NetPoller` берет управление и **освобождает `M`**.
- `M` берет другую `G2`, не простаивает.
- Когда `G1` готова, `NetPoller` ставит ее в очередь (глобальную или локальную `P`).

Это сильно уменьшает количество `M`, особенно при обработке множества сетевых соединений.



### **Состояния горутин (`G`):**

Горутина (`G`) в Go может находиться в одном из следующих состояний:

| **Состояние** | **Описание**                                                               |
| ------------- | -------------------------------------------------------------------------- |
| `_Gidle`      | Горутина не используется (обычно после завершения).                        |
| `_Grunnable`  | Горутина готова к выполнению, но ждёт в очереди `P`.                       |
| `_Grunning`   | Горутина выполняется на `M`.                                               |
| `_Gsyscall`   | Горутина заблокирована в `syscall` (ожидает завершения системного вызова). |
| `_Gwaiting`   | Горутина ожидает события (например, `channel`, `mutex`, `timer`).          |
| `_Gdead`      | Горутина завершилась и ждёт сборщика мусора.                               |
| `_Gcopystack` | Горутина увеличивает или уменьшает стек.                                   |
| `_Gscan`      | Горутина в процессе GC-сканирования (служебное состояние).                 |

**Как это работает в динамике?**

1. Горутина создаётся (`newproc()`) и становится **`_Grunnable`**.
2. `P` ставит её в локальную очередь.
3. `M` забирает её и запускает → **`_Grunning`**.
4. Если `G` блокируется (`syscall`, ожидание `chan` и т. д.) → **`_Gsyscall` или `_Gwaiting`**.
5. Когда `syscall` или ожидание завершается → горутина возвращается в **`_Grunnable`**.
6. Если горутина завершилась → **`_Gdead`**, и память под неё чистит GC.



### **Что делает `park()`?**

Функция `park()` используется, чтобы **остановить поток ОС (`M`)**, если он не нужен.

🔹 **Когда `M` паркуется?**

- Если `P` стал неактивным (нет `G` для выполнения).
- Если `P` был отвязан (например, из-за `syscall`).
- Если `GOMAXPROCS` уменьшился, и `M` больше не нужен.

🔹 **Как это выглядит?**

1. `M` понимает, что у него нет работы.
2. `M` вызывает `park()`, освобождая ресурсы ОС.
3. Если появится новая работа, `P` разбудит `M` через `runtime.notewakeup()`.



### **Что делает `handoff()`?**

Функция `handoff()` используется, чтобы **переназначить `P` другому `M`**, если текущий `M` заблокировался (`syscall`).

🔹 **Как это работает?**

1. `G1` выполняется на `M1` (привязан к `P1`).
2. `G1` вызывает `syscall`, `M1` блокируется (`_Gsyscall`).
3. `handoff()` **отвязывает `P1` от `M1`** и даёт его другому `M2`.
4. `M2` теперь выполняет горутины `P1`.
5. Когда `syscall` завершится, `M1` отправит `G1` в глобальную очередь.

🔹 **Почему это важно?**  
Без `handoff()` `P` простаивал бы, пока `M` ждёт `syscall`. Вместо этого `P` сразу продолжает работать на другом `M`.



### **Кто создаёт новую горутину?**

Горутины создаются с помощью `go func()`, что вызывает `runtime.newproc()`.

🔹 **Алгоритм `newproc()`:**

1. **Берёт `P` текущего `M`**, на котором выполняется `go func()`.
2. **Выделяет новый объект `G`**, инициализирует его стек и состояние.
3. **Добавляет `G` в локальную очередь `P`**, если есть место.
4. Если локальная очередь `P` заполнена (256 `G`), **некоторые `G` сбрасываются в глобальную очередь**.



*Дополнительно:*

- https://habr.com/ru/users/not91/publications/articles/

- https://habr.com/ru/articles/333654/

- https://habr.com/ru/articles/502506/